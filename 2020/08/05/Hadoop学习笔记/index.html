<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Hadoop学习笔记 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="第一天：多线程没用的时候就必须多进程了多进程共享数据就必须涉及很多问题（网络通信）但是业务逻辑却很简单代价高！！！ hadoop是个平台搜索引擎工作原理：爬虫（网络I&#x2F;O）-&gt;海量数据的存储-&gt;搜索（数据分析）-&gt;lucene-&gt;索引库 hadoop擅长日志分析（海量离线数据）           监控系统 第二天很多个节点叫做DataNode，又很多文件往里面存，会将文件">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop学习笔记">
<meta property="og:url" content="http://yoursite.com/2020/08/05/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="第一天：多线程没用的时候就必须多进程了多进程共享数据就必须涉及很多问题（网络通信）但是业务逻辑却很简单代价高！！！ hadoop是个平台搜索引擎工作原理：爬虫（网络I&#x2F;O）-&gt;海量数据的存储-&gt;搜索（数据分析）-&gt;lucene-&gt;索引库 hadoop擅长日志分析（海量离线数据）           监控系统 第二天很多个节点叫做DataNode，又很多文件往里面存，会将文件">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-08-05T08:33:47.844Z">
<meta property="article:modified_time" content="2020-08-05T08:34:08.417Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Hadoop学习笔记" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/08/05/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="article-date">
  <time datetime="2020-08-05T08:33:47.844Z" itemprop="datePublished">2020-08-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Hadoop学习笔记
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>第一天：<br>多线程没用的时候就必须多进程了<br>多进程共享数据就必须涉及很多问题（网络通信）<br>但是业务逻辑却很简单<br>代价高！！！</p>
<p>hadoop是个平台<br>搜索引擎工作原理：爬虫（网络I/O）-&gt;海量数据的存储-&gt;搜索（数据分析）-&gt;lucene-&gt;索引库</p>
<p>hadoop擅长日志分析（海量离线数据）<br>           监控系统</p>
<p>第二天<br>很多个节点叫做DataNode，又很多<br>文件往里面存，会将文件切成一个一个的块，分散的存储到集群里面。<br>每一个块在集群里面可以存多个副本（解决服务器故障导致的数据丢失）<br>客户端不会知道具体访问哪个块，而是指定目录名<br>所以文件之间有映射关系（Namenode）：负责把HDFS中文件抽象的路径映射到具体的哪一台机器上（block块）<br>所以客户端不管是读或者写，都先得访问Namenode</p>
<p>怎么计算海量数据的计算：并非的进行<br>阶段1：Map阶段对本地局部进行处理，并发执行<br>阶段2：Reduce阶段只在一台机器（节点）上运行，通过网络将map的中间结果取出来，再汇总下。<br>将计算过程并发化了。<br>reduce：分组统计：按月份（12个reduce）reduce又可以并发进行了。</p>
<p>第三天<br>1、zxvf<br>z:gz格式 x：解压 v：显示进度 f：对应哪个文件<br>2、hadoop文件下：sbin：系统的一些脚本  etc：配置文件  lib：本地jar包<br>share：doc可以删除<br>3、关闭防火墙：hadoop就是内网使用的<br>sudo service iptables stop<br>/usr/local/hadoop/tmp/dfs/name/current/fsimage_0000000000000003410是元数据HDFS    里面的某一个目录<br>namenode就是管理元数据的，元数据是HDFS里面的某一个目录，某一个文件，对应的有哪些切块，那些切块分别在哪些datanode上面，这些信息的管理就是元数据。<br>start-dfs.sh:    启动hdfs：存数据，读数据<br>第四天：<br>master：50070访问HDFS页面<br>访问一个HDFS客户端：Linux向HDFS（抽象的）上传文件命令：<br>fs -put word.txt hdfs://Master:9000/<br>删除本地的word.txt是主机本地内容删除了，但是HDFS的分布式文件系统中还有。<br>word.txt被DataNode切成好几个分块不是完整的存储在DataNode所在的文件系统里面，绝不会出现在本地文件系统里面。<br>放在哪里了呢？<br>/usr/local/hadoop/tmp/dfs/name里，下载的时候从name取出来，通过HTTP协议传输<br>下载文件命令：<br>hadoop fs -get hdfs://master:9000/word.txt</p>
<p>运行一个MapReduce程序命令：<br>hadoop jar hadoop-mapreduce-examples-2.7.1.jar pi 5 5</p>
<p>hadoop fs –mkdir /wordcount<br>hadoop fs –mkdir /wordcount/input<br>hadoop fs –put text.txt /wordcount/input<br>/表示HDFS的根目录</p>
<p>hadoop fs –ls /wordcount/output<br>hadoop fs –cat /wordcount/          //查看文件内容</p>
<p>第五天hdfs<br>写：写入Hdfs中的文件被切块存储，随机存放到分布式主机里，主机是Datanode（Linux ext3 /home/hadoop/app/hadoop 2.4.2/data/dfs/data）<br>读：读取HDFS中的文件 namenode（管理元数据管理文件对应的块）通过网络取Datanode中的所有的文件信息</p>
<p>Hdfs的工作思想：<br>一、HDFS是通过分布式集群来存储文件，为客户端提供一个便捷的访问方式，就是一个虚拟的目录结构：hdfs：//master:9000/wordcount/input/test.txt（真实的物理机上是不存在的，客户端访问只需访问虚拟目录即可，不需要知道具体的Datanode在哪里，客户端去查询去找Hadoop给封装起来了）————–&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;百度网盘<br>二、文件存储到HDFS集群中去的时候是被切分成block<br>三、文件的block存放在若干台datanode节点上<br>四、HDFS文件系统中的文件与真实的block之间有映射关系，由namenode管理。<br>五、每一个block在集群中会存储多个副本，好处是提高数据的可靠性，还可以提高访问的吞吐量与并发。</p>
<p>第六天<br>HDFS Shell操作<br>hadoop fs讲解<br>1、HDFS的文件无法修改，因为文件已经划分为块了<br>[-appendToFile <localsrc> … <dst>] 支持追加<br>2、    [-cat [-ignoreCrc] <src> …] 查看文本内容<br>3、    [-checksum <src> …] 算文件校验和<br>4、drwxr-xr-x  d表示是文件夹  前三个：文件所属用户对该文件的权限<br>                            第二个三元组：所属组对它的权限<br>                                第三个三元：其他用户<br>5、-rw-r–r–   2 hadoop supergroup          0 2020-07-19 22:15 /word.txt  2是副本数量，配置文件配置过：      <property><br>                <name>dfs.replication</name><br>                <value>2</value><br>                      </property><br>6、    [-chown [-R] [OWNER][:[GROUP]] PATH…] 更改文件所属主与组<br>hadoop fs -chown angelababy:mygilrs /word.txt<br>说明Hadoop权限的检查是很弱的，不管用户是否存在<br>7、    [-chmod [-R] &lt;MODE[,MODE]… | OCTALMODE&gt; PATH…] 更改权限<br>hadoop fs -chmod 777 /word.txt<br>8、    [-copyFromLocal [-f] [-p] [-l] <localsrc> … <dst>] 从本地拷贝文件到HDFS中<br>hadoop fs -copyFromLocal ./core-site.xml /<br>作用与put一样<br>9、    [-copyToLocal [-p] [-ignoreCrc] [-crc] <src> … <localdst>]<br>用于与get一致<br>10、df查看磁盘空间<br>hadoop fs -df -h /<br>11、du看目录下文件的大小<br>hadoop fs -du -s -h hdfs://master:9000/</localdst></src></dst></localsrc></src></src></dst></localsrc></p>
<p>12、hadoop fs –mkdir /aa  注意不会级联创建<br>13、hadoop fs –rm     删除文件<br>hadoop fs –rm –r 递归删除<br>14、-tail看一个文件的尾部（看日志） -f 可以实时刷新<br>注意：在业务系统里面我们是调用API来用</p>
<p>第七天：<br>hadoop集群搭建的无密登陆配置<br>1、SSH是怎么回事<br>Hadoop集群搭建的无密登陆配置<br>Ls - a可以访问linux的隐藏文件 带点号.的是隐藏文件（.ssh）<br>流程分析</p>
<p>第八天NN元数据管理机制<br>大量小文件会浪费元数据空间，分析元数据效率也会降低<br>1、Namenode元数据格式</p>
<p>其中 fsimage edits是保存在磁盘中的所以不怕断电，查询也能保证速度，在内存中查询，写的话先在edits中的，断电也会有，fsimage隔一段时间也会追上去因为SN上的Checkpoint操作<br>fsimage保存了最新的元数据检查点，包含了整个HDFS文件系统的所有目录和文件的信息。对于文件来说包括了数据块描述信息、修改时间、访问时间等；对于目录来说包括修改时间、访问权限控制信息(目录所属用户，所在组)等。<br>editlog主要是在NameNode已经启动情况下对HDFS进行的各种更新操作进行记录，HDFS客户端执行所有的写操作都会被记录到editlog中。</p>
<p>Secondary namenode的工作流程<br>1、Secondary通知Namenode切换edits文件（edits.new）<br>2、secondary从namenode获得fsimage和edits（通过http）<br>3、Secondary将fsimage载入内存，然后开始合并edits，成为fsImage.checkpoint文件<br>4、Secondary将新的fsimage发回给namenode<br>5、Namenode用新的faimage替换旧的faimage</p>
<p>什么时候做Checkpoint<br>Fs.checkpoint.period指定两次checkpoint的最大时间间隔，默认为3600秒<br>fs.checkpoin.size规定edits文件的最大值，一旦超过这个值则强制checkpoint，默认为64M。<br>第九天<br>HADOOP非HA下，集群可能会停止服务，虽然元数据可以恢复，但是确实在修复之前不能对外提供服务。</p>
<p>第十天<br>DataNode工作原理<br>提供真实文件数据的存储服务<br>文件块（block）最基本的存储单位，dfs.block.size去调整默认的block大小，根据数据的特点来调整<br>不满一个块的大小的话，还是会占一个元数据的大小</p>
<p>每个block还会有副本数，hdfs-site.xml的dfs.replication属性<br>文件块存放在 ：<br>/usr/local/hadoop/tmp/dfs/data/current/BP-1231803352-192.168.0.106-1596268895233/current/finalized</p>
<p>文本文件可以读的，压缩文件不可以读必须完整的才可以压缩<br>cat blk_1073741954 &gt;&gt;  blk_1073741953 &gt;&gt;  blk_1073741953 追加命令（cat  &gt;&gt;后的追加到前面的）</p>
<p>Java客户端编写<br>注意：<br>1、需要添加conf中的fs.defaultFS信息，<br>2、以及在run configuration中的用户名（windows系统下）</p>
<p>3、FileSystem是一个上层抽象类。为什么这么设计，因为hadoop文件系统和上层的别的框架是解耦和的，编程时面向抽象编程即可。<br>4、当不配置conf时，默认的conf读取的是子类中的RawLocalFileSystem，本地文件系统这个子类，当配置如下图的conf.set的时候，将会读取hdfs文件系统，即DistributedSystem，这个类认识hdfs:</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/08/05/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" data-id="ckdh5ox8a0004tkr16n7x7pk9" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/08/05/%E4%B8%80%E5%91%A8%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          一周算法总结
        
      </div>
    </a>
  
  
    <a href="/2020/08/05/Flink%20Checkpoint%E6%9C%80%E6%96%B0%E7%90%86%E8%A7%A3/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Flink Checkpoint最新理解</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">August 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">July 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/08/05/%E6%88%91%E7%9A%84%E7%AC%AC%E4%BA%8C%E7%AF%87%E6%96%87%E7%AB%A0/">我的第二篇文章</a>
          </li>
        
          <li>
            <a href="/2020/08/05/%E4%B8%80%E5%91%A8%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/">一周算法总结</a>
          </li>
        
          <li>
            <a href="/2020/08/05/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">Hadoop学习笔记</a>
          </li>
        
          <li>
            <a href="/2020/08/05/Flink%20Checkpoint%E6%9C%80%E6%96%B0%E7%90%86%E8%A7%A3/">Flink Checkpoint最新理解</a>
          </li>
        
          <li>
            <a href="/2020/07/18/Flink-%E6%BA%90%E7%A0%81%EF%BC%9ACheckpoint-%E5%85%83%E6%95%B0%E6%8D%AE%E8%AF%A6%E8%A7%A3/">Flink 源码：Checkpoint 元数据详解</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>